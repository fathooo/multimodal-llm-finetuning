{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerías necesarias\n",
    "import pandas as pd\n",
    "from transformers import ChameleonProcessor, ChameleonForConditionalGeneration, AdamW, get_scheduler, AutoConfig\n",
    "from accelerate import init_empty_weights, load_checkpoint_and_dispatch\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "from app.config.environments import TOKEN_HUGGINGFACE, MOCK_DATA_FOLDER\n",
    "\n",
    "\n",
    "if not os.path.exists(MOCK_DATA_FOLDER):\n",
    "    os.makedirs(MOCK_DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cargar imágenes desde una URL\n",
    "def load_image(url):\n",
    "    return Image.open(requests.get(url, stream=True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar mock data y guardarlo en un CSV\n",
    "# this data will be replace\n",
    "data = {\n",
    "    \"text\": [\n",
    "        \"Un perro corriendo en el parque.\",\n",
    "        \"Un gato saltando desde un árbol.\",\n",
    "        \"Un niño jugando con una pelota.\",\n",
    "        \"Un coche rojo estacionado en la calle.\",\n",
    "        \"Una hermosa puesta de sol.\",\n",
    "        \"Una taza de café en una mesa.\",\n",
    "        \"Un grupo de personas en una fiesta.\"\n",
    "    ],\n",
    "    \"image_url\": [\n",
    "        \"https://cdn.pixabay.com/photo/2022/09/11/15/06/dog-7447075_1280.jpg\",\n",
    "        \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS11VtfGtvMCf5fk33z6SSMk0KLUdtg1_OG7g&s\",\n",
    "        \"https://st2.depositphotos.com/2751239/7710/i/450/depositphotos_77108351-stock-photo-two-cute-little-kids-playing.jpg\",\n",
    "        \"https://img.freepik.com/fotos-premium/coche-rojo-esta-estacionado-calle-frente-edificio_1089043-92402.jpg\",\n",
    "        \"https://i.pinimg.com/236x/d4/8a/ea/d48aea840f5de4bcf2eb4325607b277f.jpg\",\n",
    "        \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS6fjlbTD3cmnHvy1KqXZD5b19_9nhWuEsTxg&s\",\n",
    "        \"https://img.freepik.com/fotos-premium/grupo-personas-fiesta-gorro-fiesta_670382-21629.jpg\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(MOCK_DATA_FOLDER + '/mock_data.csv', index=False)\n",
    "\n",
    "# Cargar datos del CSV\n",
    "df = pd.read_csv(MOCK_DATA_FOLDER + '/mock_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\felip\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "login(TOKEN_HUGGINGFACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: image_token, image_seq_length. \n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m processor \u001b[38;5;241m=\u001b[39m ChameleonProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/chameleon-7b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Inicializar modelo con pesos cargados usando accelerate\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mChameleonForConditionalGeneration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfacebook/chameleon-7b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     32\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\PROGRAMACION\\multimodal-llm-finetuning\\venv\\lib\\site-packages\\transformers\\modeling_utils.py:3274\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3270\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3271\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepSpeed Zero-3 is not compatible with `low_cpu_mem_usage=True` or with passing a `device_map`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3272\u001b[0m         )\n\u001b[0;32m   3273\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[1;32m-> 3274\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m   3275\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3276\u001b[0m         )\n\u001b[0;32m   3278\u001b[0m \u001b[38;5;66;03m# handling bnb config from kwargs, remove after `load_in_{4/8}bit` deprecation.\u001b[39;00m\n\u001b[0;32m   3279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_in_4bit \u001b[38;5;129;01mor\u001b[39;00m load_in_8bit:\n",
      "\u001b[1;31mImportError\u001b[0m: Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`"
     ]
    }
   ],
   "source": [
    "# # Inicializar el procesador y modelo\n",
    "# processor = ChameleonProcessor.from_pretrained(\"facebook/chameleon-7b\")\n",
    "# model = ChameleonForConditionalGeneration.from_pretrained(\"facebook/chameleon-7b\", torch_dtype=torch.bfloat16, device_map=\"cuda\")\n",
    "\n",
    "# Inicializar el procesador y modelo\n",
    "# processor = ChameleonProcessor.from_pretrained(\"facebook/chameleon-7b\")\n",
    "\n",
    "# # Inicializar modelo de forma \"vacía\"\n",
    "# config = AutoConfig.from_pretrained(\"facebook/chameleon-7b\")\n",
    "# with init_empty_weights():\n",
    "#     model = ChameleonForConditionalGeneration.from_config(config)\n",
    "\n",
    "# # Cargar pesos usando accelerate\n",
    "# model = load_checkpoint_and_dispatch(\n",
    "#     model, \"facebook/chameleon-7b\", device_map=\"auto\", dtype=torch.bfloat16\n",
    "# )\n",
    "\n",
    "# # Función para procesar y tokenizar datos\n",
    "# def process_data(text, image_url):\n",
    "#     image = load_image(image_url)\n",
    "#     inputs = processor(text, images=image, return_tensors=\"pt\").to(model.device)\n",
    "#     return inputs\n",
    "\n",
    "# Inicializar el procesador\n",
    "processor = ChameleonProcessor.from_pretrained(\"facebook/chameleon-7b\")\n",
    "\n",
    "# Inicializar modelo con pesos cargados usando accelerate\n",
    "model = ChameleonForConditionalGeneration.from_pretrained(\n",
    "    \"facebook/chameleon-7b\", \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"auto\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para procesar y tokenizar datos\n",
    "def process_data(text, image_url):\n",
    "    image = load_image(image_url)\n",
    "    inputs = processor(text, images=image, return_tensors=\"pt\").to(model.device)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "num_training_steps = len(df) * num_epochs\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for idx, row in df.iterrows():\n",
    "        text = row['text']\n",
    "        image_url = row['image_url']\n",
    "        \n",
    "        inputs = process_data(text, image_url)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        print(f'Epoch {epoch}, Step {idx}, Loss: {loss.item()}')\n",
    "\n",
    "# Guardar modelo\n",
    "model.save_pretrained('finetuned_chameleon')\n",
    "processor.save_pretrained('finetuned_processor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación\n",
    "model.eval()\n",
    "for idx, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    image_url = row['image_url']\n",
    "    \n",
    "    inputs = process_data(text, image_url)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "    \n",
    "    print(f'Input: {text}')\n",
    "    print(f'Output: {processor.decode(outputs[0], skip_special_tokens=True)}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
