version: '3.8'

services:
  app:
    build: .
    container_name: multimodal-llm-finetuning
    volumes:
      - ./model_cache:/triton_build/triton/multimodal-llm-finetuning/fine_tuned_chameleon
      - ./app:/triton_build/triton/app  # Mapea la carpeta local "app" al directorio de trabajo en el contenedor
      - ./main.py:/triton_build/triton/main.py  # Mapea el archivo local "main.py" al archivo en el contenedor
    # command:   # Comando que ejecutará tu aplicación (puedes modificarlo según tus necesidades)
    command: /bin/bash
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    stdin_open: true  # Keep stdin open for interaction
    tty: true  # Allocate a pseudo-TTY for the container
