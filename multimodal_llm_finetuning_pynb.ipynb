{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JyzU_gwAykWg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TOKEN_HUGGINGFACE'] = '<Code get HuggingFace>'\n",
        "os.environ['DOWNLOAD_DATA_DIR'] = 'app/datasets'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1o-5jEVspgaW",
        "outputId": "29bdf993-e4b8-4f72-9410-a1542d67c7ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directorio /content/drive/MyDrive/github ya existe.\n",
            "Repositorio ya existe en Google Drive. Haciendo checkout a la rama develop...\n",
            "/content/drive/MyDrive/github/multimodal-llm-finetuning\n",
            "M\trequirements.txt\n",
            "Already on 'develop'\n",
            "Your branch is up to date with 'origin/develop'.\n",
            "* \u001b[32mdevelop\u001b[m\n",
            "  main\u001b[m\n",
            "Directorio actual: /content/drive/MyDrive/github/multimodal-llm-finetuning\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Definir la ruta al directorio donde deseas almacenar el repositorio en Google Drive\n",
        "base_path = '/content/drive/MyDrive/github'\n",
        "repo_name = 'multimodal-llm-finetuning'\n",
        "repo_path = os.path.join(base_path, repo_name)\n",
        "repo_url = 'https://github.com/fathooo/multimodal-llm-finetuning.git'\n",
        "branch_name = 'develop'\n",
        "\n",
        "# Crear el directorio base si no existe\n",
        "if not os.path.exists(base_path):\n",
        "    os.makedirs(base_path)\n",
        "    print(f\"Directorio {base_path} creado.\")\n",
        "else:\n",
        "    print(f\"Directorio {base_path} ya existe.\")\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.path.exists(repo_path):\n",
        "    print(\"Repositorio no encontrado en Google Drive, clonando el repositorio...\")\n",
        "    # Clonar el repositorio si no existe y hacer checkout a la rama develop\n",
        "    !git clone {repo_url} {repo_path}\n",
        "    %cd {repo_path}\n",
        "    !git checkout {branch_name}\n",
        "    !git pull origin {branch_name}\n",
        "else:\n",
        "    print(\"Repositorio ya existe en Google Drive. Haciendo checkout a la rama develop...\")\n",
        "    %cd {repo_path}\n",
        "    !git checkout {branch_name}\n",
        "\n",
        "# Confirma que estás en la rama correcta\n",
        "!git branch\n",
        "\n",
        "# Cambiar al directorio del repositorio\n",
        "os.chdir(repo_path)\n",
        "print(\"Directorio actual:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAg8XD0ZuFsH",
        "outputId": "41c6cfe2-736e-4cd6-a7e9-8e2cdadf7698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.20)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (0.4.6)\n",
            "Requirement already satisfied: transformers==4.44.0 in /usr/local/lib/python3.10/dist-packages (4.44.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.0) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.0) (0.23.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.0) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.0) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.0) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.0) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.0) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.0) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.44.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.44.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.44.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.44.0) (2024.7.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Archivo requirements-colab.txt creado.\n"
          ]
        }
      ],
      "source": [
        "# Celda para instalar torch y CUDA desde el índice extra\n",
        "!pip install torch --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "# Celda para instalar dotenv\n",
        "!pip install python-dotenv\n",
        "# Celda para instalar colorama\n",
        "!pip install colorama\n",
        "# Celda para instalar transformers\n",
        "!pip install transformers==4.44.0\n",
        "# Celda para instalar datasets\n",
        "!pip install datasets\n",
        "\n",
        "!pip freeze > requirements-colab.txt\n",
        "print(\"Archivo requirements-colab.txt creado.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhvEWgXTrb-d",
        "outputId": "ba9ca364-7652-4d6f-fe1c-0ced89fd2711"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch Version: 2.3.1+cu121\n",
            "CUDA Version: 12.1\n",
            "CUDA available: True\n",
            "Current device: 0\n",
            "alpaca_spanish.parquet already exists in app/datasets\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "# Ejemplo de uso de funciones del módulo\n",
        "from app.config.config import print_device_info, get_device, TOKEN_HUGGINGFACE\n",
        "from app.data.download import download_datasets\n",
        "from app.config.dataset_info import dataset_info_list\n",
        "from app.utils.huggingface import hf_login\n",
        "\n",
        "# Iniciar Colorama\n",
        "from app.utils.colorama_utils import initialize_colorama\n",
        "initialize_colorama()\n",
        "\n",
        "# Obtener dispositivo\n",
        "device = get_device()\n",
        "\n",
        "# Imprimir la información del dispositivo\n",
        "print_device_info()\n",
        "\n",
        "# Descargar los datasets\n",
        "download_datasets(dataset_info_list, os.getenv('DOWNLOAD_DATA_DIR'))\n",
        "\n",
        "# Login HF\n",
        "hf_login(TOKEN_HUGGINGFACE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYP9SgTptRTa",
        "outputId": "a4b0e8d0-582b-485d-e796-6d508fa83e21"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some kwargs in processor config are unused and will not have any effect: image_token, image_seq_length. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preview of the first 3 rows of the dataset:\n",
            "                    instruction                        input                                   output\n",
            "            ¿Qué significa DNA?                              DNA significa ácido desoxirribonucleico.\n",
            "¿Cuál es la capital de Francia?                                       La capital de Francia es París.\n",
            "   Identifica el que no encaja. Twitter, Instagram, Telegram                                 Telegram\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from app.config.environments import ENV_DOWNLOAD_DATA_DIR\n",
        "from app.config.config import MODEL_NAME\n",
        "from app.utils.colorama_utils import initialize_colorama, print_message\n",
        "from app.data.preprocess import load_dataset, split_dataset\n",
        "from colorama import Fore  # Se agrega esta línea\n",
        "from transformers import ChameleonProcessor\n",
        "\n",
        "\n",
        "# Check if the file exists before loading\n",
        "# Charge the first dataset\n",
        "file_info = dataset_info_list[0]\n",
        "file_path = os.path.join(ENV_DOWNLOAD_DATA_DIR, file_info['file_name'])\n",
        "if not os.path.exists(file_path):\n",
        "    print_message(\"File does not exist.\", Fore.RED)\n",
        "\n",
        "# Initialize processor to get tokenizer\n",
        "processor = ChameleonProcessor.from_pretrained(MODEL_NAME)\n",
        "tokenizer = processor.tokenizer\n",
        "\n",
        "# Load local dataset\n",
        "df = load_dataset(file_path, file_info['format'])\n",
        "train_dataset, val_dataset = split_dataset(df, tokenizer, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsWLh5mOsu8N",
        "outputId": "c64f11ae-359d-41ea-e7d8-700b0028111a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training samples: 41553\n",
            "Number of validation samples: 10389\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of training samples: {len(train_dataset)}\")\n",
        "print(f\"Number of validation samples: {len(val_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SX_w3ZcOP4Pg",
        "outputId": "139f5ea7-4c89-4b51-9b23-f06461d965ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "if train_dataset and val_dataset:\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "    # Load model\n",
        "    # model = ChameleonForConditionalGeneration.from_pretrained(MODEL_NAME, torch_dtype=torch.bfloat16).to(device)\n",
        "    # # Train model\n",
        "    # train_model(model, train_dataset, processor, device, LEARNING_RATE, MAX_STEPS_PER_EPOCH, EPOCHS)\n",
        "    pass\n",
        "else:\n",
        "    print_message(\"Failed to load the dataset for training. Please check if the file exists and is accessible.\", Fore.RED)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
